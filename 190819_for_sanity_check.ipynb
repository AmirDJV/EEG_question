{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\Anaconda3\\envs\\mne\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "from gc import collect as clear\n",
    "from eelbrain import *\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "\n",
    "try:\n",
    "    if \"winsound\" not in sys.modules:\n",
    "        import winsound\n",
    "    def makeSound(freq = 6000, # Hz\n",
    "              duration = 3000): # millisecond\n",
    "        winsound.Beep(freq, duration)\n",
    "except ImportError:\n",
    "    if \"os\" not in sys.modules:\n",
    "        import winsound\n",
    "    def makeSound():\n",
    "        os.system('say -v Amir''s Task finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have files 283\n",
      "['data/all/N101_F010_plv.csv', 'data/all/N101_femal_plv.csv', 'data/all/N101_male_plv.csv']\n",
      "{1.0: 53.0, 2.0: 34.0, 3.0: 54.5}\n",
      "I have males: 73 \n",
      "I have females: 74 \n",
      "I have baseline: 78 \n",
      "I have eyes: 58\n"
     ]
    }
   ],
   "source": [
    "files = [x[0]+\"/\"+f for x in os.walk(\"data/all\") for f in x[2] if\n",
    "               f.endswith(\".csv\")] \n",
    "\n",
    "files = [f for f in files if f[-7:-4] == \"plv\"]\n",
    "\n",
    "files = [s for s in files if any(os.path.basename(s)[5:9] in i for i in [\"male\", \"fema\", \"F010\", \"F060\"])]\n",
    "\n",
    "#posibleIDs = list(range(120, 155)) + list(range(222, 251)) + list(range(320, 352)) +  list(range(390, 392))\n",
    "\n",
    "posibleIDs = list(range(120, 155)) + list(range(222, 251)) + list(range(310, 352)) +  list(range(390, 392))\n",
    "\n",
    "\n",
    "#files = [f for f in files if int(os.path.basename(f)[1:4]) in posibleIDs]\n",
    "\n",
    "\n",
    "print(\"I have files\", len(files))\n",
    "print(files[:3])\n",
    "\n",
    "#files = [f for f in files if os.path.basename(f)[1] != \"2\"]\n",
    "\n",
    "grps = np.zeros(len(files))\n",
    "for i, f in enumerate(files):\n",
    "    if os.path.basename(f)[1] == \"1\":\n",
    "        grps[i] = 1\n",
    "    if os.path.basename(f)[1] == \"2\":\n",
    "        grps[i] = 2\n",
    "    if os.path.basename(f)[1] == \"3\":\n",
    "        grps[i] = 3\n",
    "    \n",
    "unique, paradigm = np.unique(grps, return_counts=True)       \n",
    "print(dict(zip(unique, paradigm / 2)))\n",
    "\n",
    "male = [s for s in files if any(os.path.basename(s)[5:9] in i for i in [\"male\"])]\n",
    "female = [s for s in files if any(os.path.basename(s)[5:9] in i for i in [\"fema\"])]\n",
    "baselines = [s for s in files if any(os.path.basename(s)[5:9] in i for i in [\"F010\"])]\n",
    "eyes = [s for s in files if any(os.path.basename(s)[5:9] in i for i in [\"F060\"])]\n",
    "\n",
    "print(\"I have males:\", len(male),\n",
    "      \"\\nI have females:\", len(female), \n",
    "     \"\\nI have baseline:\", len(baselines), \n",
    "     \"\\nI have eyes:\", len(eyes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing places were I only have one male/female file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 26, 2.0: 26, 3.0: 18, 4.0: 18, 5.0: 29, 6.0: 29}\n"
     ]
    }
   ],
   "source": [
    "supportfiles = []\n",
    "for m in male: \n",
    "    for f in female: \n",
    "        if os.path.basename(m)[1:4] == os.path.basename(f)[1:4]:\n",
    "            supportfiles.append(m)\n",
    "            supportfiles.append(f)\n",
    "            \n",
    "assert len(supportfiles) % 2 == 0\n",
    "\n",
    "grps = np.zeros(len(supportfiles))\n",
    "for i, f in enumerate(supportfiles):\n",
    "    if os.path.basename(f)[1] == \"1\" and \"_m\" in os.path.basename(f):\n",
    "        grps[i] = 1\n",
    "    if os.path.basename(f)[1] == \"1\" and \"_f\" in os.path.basename(f):\n",
    "        grps[i] = 2\n",
    "    if os.path.basename(f)[1] == \"2\" and \"_m\" in os.path.basename(f):\n",
    "        grps[i] = 3\n",
    "    if os.path.basename(f)[1] == \"2\" and \"_f\" in os.path.basename(f):\n",
    "        grps[i] = 4\n",
    "    if os.path.basename(f)[1] == \"3\" and \"_m\" in os.path.basename(f):\n",
    "        grps[i] = 5\n",
    "    if os.path.basename(f)[1] == \"3\" and \"_f\" in os.path.basename(f):\n",
    "        grps[i] = 6\n",
    "    \n",
    "unique, paradigm = np.unique(grps, return_counts=True)       \n",
    "print(dict(zip(unique, paradigm)))\n",
    "\n",
    "male = [s for s in supportfiles if any(os.path.basename(s)[5:9] in i for i in [\"male\"])]\n",
    "female = [s for s in supportfiles if any(os.path.basename(s)[5:9] in i for i in [\"fema\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing baselines and eyes without support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I have baselines: 73 ['data/all/N101_F010_plv.csv', 'data/all/N121_F010_plv.csv']\n",
      "\n",
      "I have eyesfiles: 58 ['data/all/N121_F060_plv.csv', 'data/all/N122_F060_plv.csv']\n"
     ]
    }
   ],
   "source": [
    "baselinefiles = []\n",
    "for b in baselines: \n",
    "    for s in supportfiles: \n",
    "        if (os.path.basename(b)[1:4] == os.path.basename(s)[1:4]) and (b not in baselinefiles):\n",
    "            baselinefiles.append(b)\n",
    "\n",
    "eyesfiles = []\n",
    "for e in eyes: \n",
    "    for s in baselines: \n",
    "        if (os.path.basename(e)[1:4] == os.path.basename(s)[1:4]) and (e not in eyesfiles):\n",
    "            eyesfiles.append(e)\n",
    "            \n",
    "print(\"\\nI have baselines:\", len(baselinefiles), baselinefiles[:2])\n",
    "print(\"\\nI have eyesfiles:\", len(eyesfiles), eyesfiles[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have males: 73 \n",
      "I have females: 73 \n",
      "I have baseline: 73 \n",
      "I have eyes: 58\n",
      "# files I have: 277\n"
     ]
    }
   ],
   "source": [
    "print(\"I have males:\", len(male),\n",
    "      \"\\nI have females:\", len(female), \n",
    "     \"\\nI have baseline:\", len(baselinefiles), \n",
    "     \"\\nI have eyes:\", len(eyesfiles))\n",
    "\n",
    "files = supportfiles + baselinefiles + eyesfiles\n",
    "\n",
    "print(\"# files I have:\", len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting clusters/areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnames = ['Fp1-0', 'Fp2-0', 'F7-0', 'F8-0', 'F3-0', 'F4-0', 'Fz-0', 'FT9-0', 'FT10-0', 'FC5-0', 'FC1-0',\n",
    " 'FC2-0', 'FC6-0', 'T7-0', 'C3-0', 'Cz-0', 'C4-0', 'T8-0', 'TP9-0', 'CP5-0', 'CP1-0', 'CP2-0',\n",
    " 'CP6-0', 'TP10-0',  'P7-0', 'P3-0', 'Pz-0', 'P4-0', 'P8-0', 'O1-0', 'O2-0', 'Fp1-1', 'Fp2-1',\n",
    " 'F7-1', 'F8-1', 'F3-1', 'F4-1', 'Fz-1', 'FT9-1', 'FT10-1', 'FC5-1', 'FC1-1', 'FC2-1', 'FC6-1',\n",
    " 'T7-1', 'C3-1', 'Cz-1', 'C4-1', 'T8-1', 'TP9-1', 'CP5-1', 'CP1-1', 'CP2-1',  'CP6-1',  'TP10-1',\n",
    " 'P7-1',  'P3-1',  'Pz-1',  'P4-1',  'P8-1',  'O1-1', 'O2-1']\n",
    "\n",
    "center = ['Cz-0', 'Fz-0', 'Pz-0']\n",
    "\n",
    "leftFrontal = [\"Fp1-0\", \"F3-0\", \"F7-0\"]\n",
    "leftFrontalCentral = [\"FC1-0\", \"FC5-0\"]\n",
    "leftCentralParietal = [\"C3-0\", \"CP1-0\", \"CP5-0\"]\n",
    "leftParietalOoccipital = [\"P3-0\", \"P7-0\", \"O1-0\"]    \n",
    "leftTemporal = [\"FT9-0\", \"TP9-0\", \"T7-0\"]\n",
    "\n",
    "rightFrontal = [\"Fp2-0\", \"F4-0\", \"F8-0\"]\n",
    "rightFrontalCentral = [\"FC2-0\", \"FC6-0\"]\n",
    "rightCentralParietal = [\"C4-0\", \"CP2-0\", \"CP6-0\"]\n",
    "rightParietalOoccipital = [\"P4-0\", \"P8-0\", \"O2-0\"]\n",
    "rightTemporal = [\"FT10-0\", \"TP10-0\",  \"T8-0\"]\n",
    "\n",
    "roiCh = [leftTemporal, leftParietalOoccipital, leftCentralParietal, leftFrontalCentral, leftFrontal, \n",
    "        center, \n",
    "        rightFrontal, rightFrontalCentral, rightCentralParietal, rightParietalOoccipital, rightTemporal]\n",
    "\n",
    "roiNames = [\"leftTemporal\", \"leftParietalOoccipital\", \"leftCentralParietal\", \"leftFrontalCentral\", \"leftFrontal\", \n",
    "        \"center\", \n",
    "        \"rightFrontal\", \"rightFrontalCentral\", \"rightCentralParietal\", \"rightParietalOoccipital\", \"rightTemporal\"]\n",
    "\n",
    "assert len(roiCh) == len(roiNames), \"I don't have the same length of roiCh and roiNames\"\n",
    "\n",
    "roiChange = {}\n",
    "for i, c in enumerate(roiCh):\n",
    "    for n in c: \n",
    "        roiChange.update({n : roiNames[i]})\n",
    "        \n",
    "#pairs = [(ch, ch2) for i, ch in enumerate(roiNames) for ch2 in roiNames]\n",
    "#labels = [' '.join(pair) for pair in pairs]\n",
    "\n",
    "pairs = []\n",
    "for ch1 in roiNames: \n",
    "    for ch2 in roiNames: \n",
    "        if ch1 == ch2:\n",
    "            pairs.append((ch1 + \"-0\", ch2 + \"-1\"))\n",
    "labels = [' '.join(pair) for pair in pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Categorial('pair', ('leftTemporal-0 leftTemporal-1', 'leftParietalOoccipital-0 leftParietalOoccipital-1', 'leftCentralParietal-0 leftCentralParietal-1', 'leftFrontalCentral-0 leftFrontalCentral-1', 'leftFrontal-0 leftFrontal-1'))\n"
     ]
    }
   ],
   "source": [
    "connectivity = []\n",
    "for i, pair1 in enumerate(pairs):\n",
    "    ch1, ch2 = pair1\n",
    "    connectivity.append((' '.join(pair1), ' '.join(pair1)))\n",
    "\n",
    "pairs = set()\n",
    "for src, dst in connectivity:\n",
    "    a = labels.index(src)\n",
    "    b = labels.index(dst)\n",
    "    pairs.add((a, b))\n",
    "    \n",
    "connectivity = np.array(sorted(pairs), np.uint32)\n",
    "sensor_dim = Categorial(\"pair\", labels, connectivity)\n",
    "\n",
    "assert len(sensor_dim) == len(labels), \"sensor_dim and labels are not at the same length\"\n",
    "print(len(sensor_dim))\n",
    "print(sensor_dim[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building ds - the dataset\n",
    "**I take only the support files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false #Not to run\n",
    "#different variations for paradigms taking\n",
    "a = [os.path.basename(f)[:4] for f in baselinefiles]\n",
    "b = [os.path.basename(f)[:4] for f in eyesfiles]\n",
    "c = [os.path.basename(f)[:4] for f in supportfiles]\n",
    "filesToTake = list(set(b).intersection(c))\n",
    "\n",
    "a = [f for f in baselinefiles if os.path.basename(f)[:4] in filesToTake]\n",
    "b = [f for f in eyesfiles if os.path.basename(f)[:4] in filesToTake]\n",
    "c = [f for f in supportfiles if os.path.basename(f)[:4] in filesToTake]\n",
    "filesToTake = b + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesToTake = supportfiles\n",
    "\n",
    "rows = []\n",
    "rowsRaw = []\n",
    "for file in filesToTake:\n",
    "    items = os.path.basename(file)\n",
    "    subject = items[1:4]\n",
    "    condition = items[5:9]\n",
    "    group = items[1]\n",
    "    \n",
    "    df = pd.read_csv(file, usecols=['channel_1', 'channel_2', \"alpha\", \"beta\", \"gamma\"], header=0)\n",
    "    df[[\"channel_1\",\"channel_2\"]] = df[[\"channel_1\",\"channel_2\"]].replace(list(range(62)), chnames)\n",
    "    df = df[df['channel_1'].str.strip().str[-1] != df['channel_2'].str.strip().str[-1]].reset_index(drop=True)\n",
    "    df = df[df['channel_1'].str.strip().str[-1] == \"0\"]\n",
    "    df[\"channel_1\"] = df[\"channel_1\"].replace(roiChange.keys(), [ch + \"-0\" for ch in list(roiChange.values())] )\n",
    "    df[\"channel_2\"] = df[\"channel_2\"].replace([ch[:-1] + \"1\" for ch in list(roiChange.keys())], [ch + \"-1\" for ch in list(roiChange.values())] )\n",
    "    df = df[df['channel_1'].str.strip().str[:-1] == df['channel_2'].str.strip().str[:-1]].reset_index(drop=True)\n",
    "    df = df.groupby([\"channel_1\", \"channel_2\"]).mean().reset_index()\n",
    "    df.channel_1 = df.channel_1.astype('category')\n",
    "    df.channel_1.cat.categories = [ch + \"-0\" for ch in roiNames]\n",
    "    df.channel_2 = df.channel_2.astype('category')\n",
    "    df.channel_2.cat.categories = [ch + \"-1\" for ch in roiNames]\n",
    "\n",
    "    df = df.sort_values(by=[\"channel_1\",\"channel_2\"])\n",
    "    \n",
    "    rowsRaw.append(df)\n",
    "\n",
    "    data = {' '.join((ch1, ch2)): (v1, v2, v3) for ch1, ch2, v1, v2, v3 in df.values}\n",
    "    alpha = NDVar([v[0] for v in list(data.values())], sensor_dim)\n",
    "    beta = NDVar([v[1] for v in list(data.values())], sensor_dim)\n",
    "    gamma = NDVar([v[2] for v in list(data.values())], sensor_dim)\n",
    "    rows.append([subject, condition, group, alpha, beta, gamma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key         Type     Values                                                                                          \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "subject     Factor   101:2, 121:2, 122:2, 123:2, 126:2, 127:2, 128:2, 130:2, 132:2, 133:2, 134:2, 139:2... (69 cells)\n",
      "condition   Factor   male:69, fema:69                                                                                \n",
      "group       Factor   1:46, 2:36, 3:56                                                                                \n",
      "alpha       NDVar    11 pair; 0.0388517 - 0.615851                                                                   \n",
      "beta        NDVar    11 pair; 0.0496636 - 0.467749                                                                   \n",
      "gamma       NDVar    11 pair; 0.055003 - 0.440267                                                                    \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "Dataset: 138 cases\n"
     ]
    }
   ],
   "source": [
    "rowsTake = [r for r in rows if r[0] not in [\"135\", \"171\", \"304\", \"152\"]]\n",
    "ds = Dataset.from_caselist(['subject', 'condition', 'group', \"alpha\", \"beta\", \"gamma\"], rowsTake)\n",
    "ds['subject'].random = True\n",
    "\n",
    "print(ds.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 1/3 [00:20<00:41, 20.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:42<00:21, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:03<00:00, 21.03s/it]\n"
     ]
    }
   ],
   "source": [
    "#My acutal analysis with the subset of subjects I want to kickout\n",
    "#I didn't remove the \"pmin\" in order to have a stable order of ids in \"r.find_clusters\"\n",
    "freq = [\"alpha\", \"beta\", \"gamma\"]\n",
    "results = []\n",
    "for f in tqdm(freq): \n",
    "    print(f)\n",
    "    res = testnd.anova(f, 'condition * group * subject(group)',\n",
    "                       samples = 1000,  ds=ds, pmin=0.01) \n",
    "    results.append(res)\n",
    "\n",
    "makeSound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "#   Effect              f_max       p   sig\n",
      "-------------------------------------------\n",
      "0   condition            1.12   1.000      \n",
      "1   group                5.50    .020   *  \n",
      "2   condition x group    1.62   1.000      \n",
      "beta\n",
      "#   Effect              f_max       p   sig\n",
      "-------------------------------------------\n",
      "0   condition            0.56   1.000      \n",
      "1   group                6.09    .015   *  \n",
      "2   condition x group    1.62   1.000      \n",
      "gamma\n",
      "#   Effect              f_max       p   sig\n",
      "-------------------------------------------\n",
      "0   condition            0.37   1.000      \n",
      "1   group                6.46    .017   *  \n",
      "2   condition x group    0.81   1.000      \n"
     ]
    }
   ],
   "source": [
    "for f, r in zip(freq, results): \n",
    "    print(f)\n",
    "    print(r.table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rightFrontalCentral-0 rightFrontalCentral-1\n",
      "rightFrontalCentral-0 rightFrontalCentral-1\n",
      "leftCentralParietal-0 leftCentralParietal-1\n",
      "rightFrontalCentral-0 rightFrontalCentral-1\n",
      "rightTemporal-0 rightTemporal-1\n",
      "5\n",
      "[['alpha', 'rightFrontalCentral-0 rightFrontalCentral-1'], ['beta', 'rightFrontalCentral-0 rightFrontalCentral-1'], ['gamma', 'leftCentralParietal-0 leftCentralParietal-1'], ['gamma', 'rightFrontalCentral-0 rightFrontalCentral-1'], ['gamma', 'rightTemporal-0 rightTemporal-1']]\n"
     ]
    }
   ],
   "source": [
    "myCluster = []\n",
    "for f, r in zip(freq, results): \n",
    "    for i in np.array([i for i in list(r.find_clusters(0.05).values()) if i.name == \"id\"]).ravel():\n",
    "        for c, l in zip(np.array(r.cluster(i, 'group')), labels):\n",
    "            if c != 0:\n",
    "                myCluster.append([f, l])\n",
    "                print(l)\n",
    "print(len(myCluster))\n",
    "print(myCluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "id   v        p      sig   effect\n",
      "---------------------------------\n",
      "1    5.5014   0.02   *     group \n",
      "beta\n",
      "id   v        p       sig   effect\n",
      "----------------------------------\n",
      "1    6.0941   0.015   *     group \n",
      "gamma\n",
      "id   v        p       sig   effect\n",
      "----------------------------------\n",
      "1    5.1951   0.045   *     group \n",
      "2    5.4425   0.036   *     group \n",
      "3    6.4611   0.017   *     group \n"
     ]
    }
   ],
   "source": [
    "for f, r in zip(freq, results): \n",
    "    print(f)\n",
    "    print(r.find_clusters(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting to CSV the aggregated values for each cluster/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "beta\n",
      "gamma\n",
      "gamma\n",
      "gamma\n"
     ]
    }
   ],
   "source": [
    "exportData = pd.DataFrame(np.array(ds[\"subject\"]), columns = [\"id\"])\n",
    "for f, r in zip(freq, results): \n",
    "    for i in np.array([i for i in list(r.find_clusters(0.0499).values()) if i.name == \"id\"]).ravel():\n",
    "        for c, l in zip(np.array(r.cluster(i, 'group')), labels):\n",
    "            if c != 0:\n",
    "                mask = r.cluster(i, 'group') != 0\n",
    "                print(f)\n",
    "                cluster_plv = ds[f].mean(mask)\n",
    "                colName = f[0] + l.split()[0][:-2]\n",
    "                exportData[colName] = cluster_plv\n",
    "\n",
    "exportData.to_csv(\"exportData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving plots for each significant cluster/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "Prompt-toolkit does not seem to be supported by the current IPython shell (ZMQInteractiveShell); The Eelbrain GUI needs to block Terminal input to work. Use eelbrain.gui.run() to start GUI interaction.\n",
      "beta\n",
      "gamma\n",
      "gamma\n",
      "gamma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotsFolder = \"plots/support vs baseline/\" \n",
    "plotsFolder = \"plots/eyes vs baseline/\" \n",
    "plotsFolder = \"plots/eyes vs baseline vs support/\" \n",
    "plotsFolder = \"plots/eyes vs support/\" \n",
    "plotsFolder = \"plots/temp/\" \n",
    "\n",
    "\n",
    "plots = []\n",
    "count = 0\n",
    "for f, r in zip(freq, results): \n",
    "    for i in np.array([i for i in list(r.find_clusters(0.0499).values()) if i.name == \"id\"]).ravel():\n",
    "        for c, l in zip(np.array(r.cluster(i, 'group')), labels):\n",
    "            if c != 0:\n",
    "                count += 1\n",
    "                mask = r.cluster(i, 'group') != 0\n",
    "                print(f)\n",
    "                cluster_plv = ds[f].mean(mask)\n",
    "                title = l.split()[0][:-2]\n",
    "                plot.Barplot(cluster_plv, 'group', ds=ds, show = False, title = title, tight = True).save(plotsFolder + f + title + \".jpg\")\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
